
import os
import pandas as pd
import requests
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import timedelta
import datetime as dt

from run_all import COUNTIES


def openet_get_fields_export(fields, start, end, et_too=False,
                             api_key='C:/Users/CND571/Documents/Haugen_Montana_API.txt'):
    """ Uses OpenET API multipolygon export endpoint to get etof data given a Google Earth Engine asset.
    Files will be exported to user's Google Drive; this is dependent on linking OpenET account to a Google account
    (I think).

    :fields: path to gee asset, form of 'projects/cloud_project/assets/asset_filename'
    :start: beginning of period of study, 'YYYY-MM-DD' format
    :end: end of period of study, 'YYYY-MM-DD' format
    :et_too: if True, also download OpenET ensemble ET over same time period and set of fields
    :api_key: path to local .txt file where API key from user's OpenET account is stored. Key is first line in file.
    """

    # Use earth engine and gsutil to upload shapefiles to earth engine and then download resulting files from bucket.

    # This is apparently better, as it makes sure to close the file.
    with open(api_key, 'r') as f:
        api_key = f.readline()

    # key_file = open(api_key, "r")
    # api_key = key_file.readline()

    # set your API key before making the request
    header = {"Authorization": api_key}

    # endpoint arguments
    args = {
        "date_range": [
            start,
            end
        ],
        "interval": "monthly",
        "asset_id": fields,
        "attributes": [
            "FID"
        ],
        "reducer": "mean",
        "model": "Ensemble",
        "variable": "ETof",  # "ETof" or "ET"
        "reference_et": "gridMET",
        "units": "in"
    }

    # query the api
    resp = requests.post(
        headers=header,
        json=args,
        url="https://openet-api-montana-ic5gyecbva-uw.a.run.app/raster/export/multipolygon"
    )
    print(resp.json())
    response = resp.json()
    # tag = response['name']
    # print(tag)

    if et_too:
        # getting et variable too, in separate file.
        args.update({"variable": "ET"})
        resp = requests.post(
            headers=header,
            json=args,
            url="https://openet-api-montana-ic5gyecbva-uw.a.run.app/raster/export/multipolygon"
        )
        print(resp.json())


def get_all_openet_etof_data():
    """ Run openet_get_fields_export for all MT counties.
    This should be changed later on to put both periods in the same retrieval, but that's not working right now.
    """
    gee_county_files = ['001', '003', '005', '007', '009', '013', '015', '017', '019', '021', '023', '027', '029',
                        '031a', '031b', '033', '035', '037', '039', '041', '043', '045', '047a', '047b', '049',
                        '051', '053', '055', '057', '059', '061', '063', '065', '067', '069', '071', '073a', '073b',
                        '075', '077', '079', '081a', '081b', '083', '085', '087', '089', '091', '093', '095', '097',
                        '099a', '099b', '101', '103', '105a', '105b', '107', '111a', '111b']
    # '011', '025' and '109' no fields in 15FEB24 Statewide Irrigation Dataset.
    # Period of record for OpenET final data: 2016, provisional back to 1985.
    start_por = "1985-01-01"
    end_por = "2023-12-31"
    # Fetching old and new data separately.
    for i in tqdm(gee_county_files, total=len(gee_county_files)):
        gee_asset = 'projects/ee-hehaugen/assets/SID_15FEB2024/{}'.format(i)
        old_start, old_end = "1985-01-01", "2015-12-31"
        new_start, new_end = "2016-01-01", "2023-12-31"
        openet_get_fields_export(gee_asset, new_start, new_end)
        openet_get_fields_export(gee_asset, old_start, old_end)


def rename_etof_downloads(path):
    """ Rename OpenET etof files from 'ensemble_etof_XXXXX.csv' to 'ensemble_etof_XXX_XXXX_XXXX.csv'

    Starts out with a random 5-character suffix generated by OpenET API, then gets renamed with FIPS county code,
    first year in timeseries, and last year in time series. Harmless if run multiple times.

    path: str, specifies local directory where all etof files are stored.
    """
    for i in os.listdir(path):
        oldpath = os.path.join(path, i)
        file = pd.read_csv(oldpath, index_col='time')
        file.index = pd.to_datetime(file.index)
        srt = file.index.min().year
        end = file.index.max().year
        county = file['FID'].iloc[0][:3]  # Or maybe 'fid'
        newname = 'ensemble_etof_{}_{}_{}.csv'.format(county, srt, end)
        newpath = os.path.join(path, newname)
        os.rename(oldpath, newpath)


def check_etof_data(counties, etof_dir, plot=False):
    """ To be used after openet_get_fields_export to check data quality, and before loading any data into db files.
    """
    # TODO: change to reflect the two separate files for historic and recent data.
    bad_counties = 0
    for i in counties:
        # Setting up
        path = os.path.join(etof_dir, "ensemble_monthly_etof_{}.csv".format(i))
        etof_data = pd.read_csv(path)
        etof_data['time'] = pd.to_datetime(etof_data['time'])
        start = etof_data['time'].min()
        end = etof_data['time'].max()
        etof_data['time'] = etof_data['time'] + timedelta(days=14)
        points_exp = pd.date_range(start, end, freq='MS') + timedelta(days=14)
        num_points_exp = len(points_exp)
        fields = etof_data['fid'].unique()

        # Finding/reporting weird data
        missing = {}
        toomany = {}
        for j in fields:
            num_points_act = len(etof_data[etof_data['fid'] == j])

            if num_points_act != num_points_exp:
                # print("Mismatch in {} time series: there are {} data points when {} are expected."
                #       .format(j, num_points_act, num_points_exp))
                this_field = etof_data[etof_data['fid'] == j]
                one = set(points_exp)
                two = set(this_field['time'])
                if num_points_act < num_points_exp:
                    missing[j] = list(one.difference(two))
                    # print('Missing points:', missing[j])
                    # print()
                elif num_points_act > num_points_exp:
                    toomany[j] = list(two.difference(one))
                    # print('Additional points:', toomany[j])
                    # print()
        all_miss = sum([len(missing[x]) for x in missing if isinstance(missing[x], list)])
        set_miss = len(set(val for lis in missing.values() for val in lis))
        all_dupe = sum([len(toomany[x]) for x in toomany if isinstance(toomany[x], list)])
        set_dupe = len(set(val for lis in toomany.values() for val in lis))
        print('\n{} {} County ({} fields)'.format(i, COUNTIES[i], len(fields)))
        if len(missing)+len(toomany) > 0:
            print('----------------------------------')
            print('{} fields with missing months: {}'.format(len(missing), missing))
            print('{} total data points missing, over {} unique months. \n'.format(all_miss, set_miss))
            print('{} fields with duplicated months: {}'.format(len(toomany), toomany))
            print('{} total duplicate data points, over {} unique months.'.format(all_dupe, set_dupe))
            bad_counties += 1
        else:
            print('No errors.')

        # mean growing season vs winter etof

        etof_data['mday'] = ['{}-{}'.format(x.month, x.day) for x in etof_data['time']]
        target_range = pd.date_range('2000-4-1', '2000-9-30')
        accept = ['{}-{}'.format(x.month, x.day) for x in target_range]
        etof_data['mask'] = [1 if d in accept else 0 for d in etof_data['mday']]
        etof_data_gs = etof_data[etof_data['mask'] == 1]
        etof_data_ds = etof_data[etof_data['mask'] == 0]

        ygs = etof_data_gs['etof'].mean()
        yds = etof_data_ds['etof'].mean()

        # Plotting
        if plot:
            plt.figure()
            plt.title("{} {} County ({} fields)".format(i, COUNTIES[i], len(fields)))
            # Highlighting the growing season (April through September, inclusive)
            for j in range(start.year, end.year+1):
                if j == start.year:
                    plt.axvspan(dt.date(j, 4, 1), dt.date(j, 10, 1), alpha=0.15, zorder=0,
                                label='Growing Season (Apr-Sep)')
                else:
                    plt.axvspan(dt.date(j, 4, 1), dt.date(j, 10, 1), alpha=0.15, zorder=0)

            # Quick distribution of etof values in this county's fields over time.
            plt.scatter(etof_data['time'], etof_data['etof'], c='k', alpha=8/len(fields), edgecolors='none', zorder=2)

            # # Plotting individual field time series.
            # for j in fields[:10]:
            #     etof_field = etof_data[etof_data['fid'] == j]
            #     plt.plot(etof_field['time'], etof_field['etof'], label=j[-3:], zorder=3)

            # Plotting missing/additional data, lines get bolder with additional fields missing months on the same date.
            first_m = 0
            for k, v in missing.items():
                if first_m == 0:
                    plt.vlines(v, 0, 1.2, alpha=0.1, color='tab:orange', label='Missing Dates ({})'
                               .format(all_miss))
                    first_m = 1
                else:
                    plt.vlines(v, 0, 1.2, alpha=0.1, color='tab:orange')
            first_t = 0
            for k, v in toomany.items():
                if first_t == 0:
                    plt.vlines(v, 0, 1.2, alpha=0.1, color='tab:green', label='Duplicated Dates')
                    first_t = 1
                else:
                    plt.vlines(v, 0, 1.2, alpha=0.1, color='tab:orange')

            # mean growing season vs winter etof
            plt.hlines(ygs, dt.date(2016, 1, 1), dt.date(2023, 1, 1),
                       'tab:orange', zorder=4, label='Growing Season Mean etof: {:.2f}'.format(ygs))
            plt.hlines(yds, dt.date(2016, 1, 1), dt.date(2023, 1, 1),
                       'tab:blue', zorder=4, label='Dormant Season Mean etof: {:.2f}'.format(yds))

            # Formatting stuff
            plt.hlines([0, 1], dt.date(2016, 1, 1), dt.date(2023, 1, 1),
                       'k', zorder=4)
            plt.grid(zorder=1)
            plt.xlim(dt.date(2016, 1, 1), dt.date(2023, 1, 1))
            plt.ylim(0, 1.2)
            plt.ylabel('etof')
            plt.legend()
    print('----------------------------------------')
    print('{}/{} total counties with some weird data.'.format(bad_counties, len(counties)))
    if plot:
        plt.show()


if __name__ == '__main__':
    # STEP 1: Get the data from Openet to Google Drive
    # get_all_openet_etof_data()

    # STEP 2: Download files manually to path specified below, rename files to something useful.
    path_ = 'C:/Users/CND571/Documents/Data/etof_files'
    # rename_etof_downloads(path_)

    # STEP 3: Data quality checks
    # cnty = ['019', '033', '051', '061', '091', '101']
    # cnty = list(COUNTIES.keys())[0]
    # check_etof_data(cnty, path_, True)
# ========================= EOF ====================================================================
